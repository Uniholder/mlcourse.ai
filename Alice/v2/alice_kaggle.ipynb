{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "essential-training",
   "metadata": {},
   "source": [
    "### Good ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-revolution",
   "metadata": {},
   "source": [
    "- bag of sites 1,2,3-grams\n",
    "- time-aware cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-authentication",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ongoing-nightmare",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train.todense() # MemoryError: Unable to allocate 78.6 GiB for an array with shape (253561, 41592) and data type int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-durham",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-notification",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-particle",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-catalyst",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%alias head powershell -command \"& {Get-Content %s -Head 10}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interracial-import",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function for writing predictions\n",
    "def write_to_submission_file(predicted_labels, out_file, target='target', index_label='session_id'):\n",
    "    predicted_df = pd.DataFrame(predicted_labels, index=np.arange(1, predicted_labels.shape[0] + 1), columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-texas",
   "metadata": {},
   "source": [
    "### Data Downloading and Transformation\n",
    "\n",
    "First, read the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "democratic-judge",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train_sessions.csv', index_col='session_id', parse_dates=['time1'])\n",
    "test_df = pd.read_csv('./data/test_sessions.csv', index_col='session_id', parse_dates=['time1'])\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Extract labels\n",
    "y_train = train_df.target.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "nervous-norwegian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21), (82797, 20))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "worth-words",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    251264\n",
       "1      2297\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "unusual-reproduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2                time2  site3  \\\n",
       "session_id                                                                 \n",
       "21669          56 2013-01-12 08:05:57   55.0  2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0  2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0  2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0  2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0  2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                          time3  site4                time4  site5  \\\n",
       "session_id                                                           \n",
       "21669                       NaN    NaN                  NaN    NaN   \n",
       "54843       2013-01-12 09:07:07   55.0  2013-01-12 09:07:09    NaN   \n",
       "77292       2013-01-12 08:50:15  946.0  2013-01-12 08:50:15  946.0   \n",
       "114021      2013-01-12 08:50:18  948.0  2013-01-12 08:50:18  945.0   \n",
       "146670      2013-01-12 08:50:20  947.0  2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                          time5  ...                  time6  site7  \\\n",
       "session_id                       ...                                 \n",
       "21669                       NaN  ...                    NaN    NaN   \n",
       "54843                       NaN  ...                    NaN    NaN   \n",
       "77292       2013-01-12 08:50:16  ...    2013-01-12 08:50:16  948.0   \n",
       "114021      2013-01-12 08:50:18  ...    2013-01-12 08:50:18  947.0   \n",
       "146670      2013-01-12 08:50:21  ...    2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                          time7  site8                time8  site9  \\\n",
       "session_id                                                           \n",
       "21669                       NaN    NaN                  NaN    NaN   \n",
       "54843                       NaN    NaN                  NaN    NaN   \n",
       "77292       2013-01-12 08:50:16  784.0  2013-01-12 08:50:16  949.0   \n",
       "114021      2013-01-12 08:50:19  945.0  2013-01-12 08:50:19  946.0   \n",
       "146670      2013-01-12 08:50:21  951.0  2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                          time9 site10               time10 target  \n",
       "session_id                                                          \n",
       "21669                       NaN    NaN                  NaN      0  \n",
       "54843                       NaN    NaN                  NaN      0  \n",
       "77292       2013-01-12 08:50:17  946.0  2013-01-12 08:50:17      0  \n",
       "114021      2013-01-12 08:50:19  946.0  2013-01-12 08:50:20      0  \n",
       "146670      2013-01-12 08:50:22  947.0  2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "passive-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 253561 entries, 21669 to 204762\n",
      "Data columns (total 21 columns):\n",
      "site1     253561 non-null int64\n",
      "time1     253561 non-null datetime64[ns]\n",
      "site2     250098 non-null float64\n",
      "time2     250098 non-null object\n",
      "site3     246919 non-null float64\n",
      "time3     246919 non-null object\n",
      "site4     244321 non-null float64\n",
      "time4     244321 non-null object\n",
      "site5     241829 non-null float64\n",
      "time5     241829 non-null object\n",
      "site6     239495 non-null float64\n",
      "time6     239495 non-null object\n",
      "site7     237297 non-null float64\n",
      "time7     237297 non-null object\n",
      "site8     235224 non-null float64\n",
      "time8     235224 non-null object\n",
      "site9     233084 non-null float64\n",
      "time9     233084 non-null object\n",
      "site10    231052 non-null float64\n",
      "time10    231052 non-null object\n",
      "target    253561 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(9), int64(2), object(9)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "funded-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load websites dictionary\n",
    "with open('./data/site_dic.pkl', mode='rb') as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-debut",
   "metadata": {},
   "source": [
    "**Tranform data into format which can be fed into `CountVectorizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "facial-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 21), (82797, 20))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [f'site{s}' for s in range(1, 11)]\n",
    "train_df[sites].fillna(0).astype('int').to_csv('train_sessions_text.txt', sep=' ', index=0, header=0)\n",
    "test_df[sites].fillna(0).astype('int').to_csv('test_sessions_text.txt', sep=' ', index=0, header=0)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "mounted-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 55 0 0 0 0 0 0 0 0\n",
      "56 55 56 55 0 0 0 0 0 0\n",
      "946 946 951 946 946 945 948 784 949 946\n",
      "945 948 949 948 945 946 947 945 946 946\n",
      "947 950 948 947 950 952 946 951 946 947\n",
      "952 947 953 946 947 946 953 955 946 947\n",
      "953 947 946 953 955 947 953 946 953 1033\n",
      "946 947 954 953 946 954 946 956 957 956\n",
      "946 956 946 946 955 954 946 946 946 948\n",
      "948 946 948 784 49 53 812 982 52 52\n"
     ]
    }
   ],
   "source": [
    "%head train_sessions_text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-hampton",
   "metadata": {},
   "source": [
    "**Fit `CountVectorizer` and transform data with it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "hollywood-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253561, 50000) (82797, 50000)\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv = CountVectorizer(ngram_range=(1, 3), max_features=50000)\n",
    "with open('train_sessions_text.txt') as input_train_file:\n",
    "    X_train = cv.fit_transform(input_train_file)\n",
    "with open('test_sessions_text.txt') as input_test_file:\n",
    "    X_test = cv.transform(input_test_file)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-heading",
   "metadata": {},
   "source": [
    "### Training the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "minus-prospect",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, random_state=17, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "chinese-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(estimator=logit, X=X_train, y=y_train, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "welcome-proposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.89839966,  0.81991253,  0.86607294,  0.90081044,  0.910932  ]),\n",
       " 0.87922551345871847)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "exclusive-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "southeast-ribbon",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.885\n",
    "# logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "# write_to_submission_file(predicted_labels=logit_test_pred, out_file='logit_subm1.txt') # 0.90703 ROC AUC Public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "interracial-wagon",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.962 CV without sorting\n",
    "# logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "# write_to_submission_file(predicted_labels=logit_test_pred, out_file='logit_subm2.txt') # 0.90703 ROC AUC Public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "further-image",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.879 + 2-grams + 3-grams ???\n",
    "# logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "# write_to_submission_file(predicted_labels=logit_test_pred, out_file='logit_subm4.txt') # 0.91288"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-stand",
   "metadata": {},
   "source": [
    "### Time series cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "precise-moral",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "waiting-phoenix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((23051,), (23051,)),\n",
       " ((46102,), (23051,)),\n",
       " ((69153,), (23051,)),\n",
       " ((92204,), (23051,)),\n",
       " ((115255,), (23051,)),\n",
       " ((138306,), (23051,)),\n",
       " ((161357,), (23051,)),\n",
       " ((184408,), (23051,)),\n",
       " ((207459,), (23051,)),\n",
       " ((230510,), (23051,))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(el[0].shape, el[1].shape) for el in time_split.split(X_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-queens",
   "metadata": {},
   "source": [
    "**Perform time series cross-validation with logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fourth-thermal",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1, random_state=17, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abandoned-today",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "olympic-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.83141992,  0.64671142,  0.87992077,  0.9631551 ,  0.84221742,\n",
       "         0.87840646,  0.94476054,  0.85321691,  0.92987691,  0.90752702]),\n",
       " 0.8677212449964109)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-checklist",
   "metadata": {},
   "source": [
    "**Train logistic regression with all training data, make predictions for test set and form a submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "alternative-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "injured-regression",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.866\n",
    "# logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "# write_to_submission_file(logit_test_pred, 'logit_subm3.csv') # 0.90804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "increasing-spring",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.868 + n-grams (1,2,3)\n",
    "# logit_test_pred = logit.predict_proba(X_test)[:, 1]\n",
    "# write_to_submission_file(logit_test_pred, 'logit_subm5.csv') # 0.91288"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-teddy",
   "metadata": {},
   "source": [
    "**Now we'll add some time features: indicators of morning, day, evening and night**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "parallel-enhancement",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_time_features(df, X_sparse):\n",
    "    hour = df['time1'].apply(lambda ts: ts.hour)\n",
    "    morning = ((hour >= 7) & (hour <= 11)).astype('int')\n",
    "    day = ((hour >= 12) & (hour <= 18)).astype('int')\n",
    "    evening = ((hour >= 19) & (hour <= 23)).astype('int')\n",
    "    night = ((hour >= 0) & (hour <= 6)).astype('int')\n",
    "    X = hstack([X_sparse, morning.values.reshape(-1, 1), \n",
    "                day.values.reshape(-1, 1), evening.values.reshape(-1, 1), \n",
    "                night.values.reshape(-1, 1)])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "imposed-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_new = add_time_features(train_df.fillna(0), X_train)\n",
    "X_test_new = add_time_features(test_df.fillna(0), X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "underlying-blowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((253561, 50004), (82797, 50004))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new.shape, X_test_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-tours",
   "metadata": {},
   "source": [
    "**Performing time series cross-validation, we see an improvement in ROC AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "frequent-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = cross_val_score(logit, X_train_new, y_train, cv=time_split, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "comprehensive-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.87652191,  0.75129605,  0.93062022,  0.978644  ,  0.90399606,\n",
       "         0.93831555,  0.96249405,  0.92731303,  0.9488597 ,  0.94043603]),\n",
       " 0.91584966011188196)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-rapid",
   "metadata": {},
   "source": [
    "**Making a new submission, we notice a leaderboard score improvement as well. Correlated CV and LB improvements is a good justifications for added features being useful and CV scheme being correct**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "wrong-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fifty-voluntary",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.916\n",
    "logit_test_pred = logit.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'logit_subm6.csv') # 0.93842"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-mission",
   "metadata": {},
   "source": [
    "**Now we tune regularization parameter C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "spanish-guarantee",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_values = np.logspace(-2, 2, 10)\n",
    "\n",
    "logit_grid_searcher = GridSearchCV(estimator=logit, param_grid={'C': c_values}, scoring='roc_auc', \n",
    "                                   n_jobs=-1, cv=time_split, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "reasonable-electronics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(n_splits=10), error_score='raise',\n",
       "       estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': array([  1.00000e-02,   2.78256e-02,   7.74264e-02,   2.15443e-01,\n",
       "         5.99484e-01,   1.66810e+00,   4.64159e+00,   1.29155e+01,\n",
       "         3.59381e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=4)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logit_grid_searcher.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "traditional-promotion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91737737315316847, {'C': 0.21544346900318834})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_grid_searcher.best_score_, logit_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "german-herald",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV 0.917\n",
    "logit_test_pred = logit_grid_searcher.predict_proba(X_test_new)[:, 1]\n",
    "write_to_submission_file(logit_test_pred, 'logit_subm7.csv') # 0.94242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-academy",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
